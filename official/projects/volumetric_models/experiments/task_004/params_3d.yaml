runtime:
  all_reduce_alg: null
  batchnorm_spatial_persistent: false
  dataset_num_private_threads: null
  default_shard_dim: -1
  distribution_strategy: mirrored
  enable_xla: false
  gpu_thread_mode: null
  loss_scale: null
  mixed_precision_dtype: float32
  num_cores_per_replica: 1
  num_gpus: 1
  num_packs: 1
  per_gpu_thread_count: 0
  run_eagerly: false
  task_index: -1
  tpu: null
  tpu_enable_xla_dynamic_padder: null
  worker_hosts: null
task:
  eval_input_partition_dims: []
  evaluation:
    report_per_class_metric: True
  init_checkpoint: null
  init_checkpoint_modules: all
  losses:
    l2_weight_decay: 0.0
    loss_type: null
  model:
    backbone:
      type: unet_3d
      unet_3d:
        base_filters: 32
        kernel_size: !!python/tuple
        - 3
        - 3
        - 3
        model_id: 4  #
        pool_size: !!python/tuple
        - 2
        - 2
        - 2
        use_batch_normalization: true
    decoder:
      type: unet_3d_decoder
      unet_3d_decoder:
        kernel_size: !!python/tuple
        - 3
        - 3
        - 3
        model_id: 4  #
        pool_size: !!python/tuple
        - 2
        - 2
        - 2
        use_batch_normalization: true
        use_deconvolution: true
    head:
      level: 1
      num_classes: 3  #
      num_convs: 0
      num_filters: 256
      output_logits: true
      upsample_factor: 1
      use_batch_normalization: true
    input_size: [40, 56, 40]  #
    max_level: 7  #
    min_level: 3
    norm_activation:
      activation: relu
      norm_epsilon: 0.001
      norm_momentum: 0.99
      use_sync_bn: false
    num_channels: 1  #
    num_classes: 3  #
  train_data:
    block_length: 1
    cache: false
    cycle_length: 10
    deterministic: null
    drop_remainder: false
    dtype: float32
    enable_tf_data_service: false
    file_type: tfrecord
    global_batch_size: 2  #
    image_field_key: image/encoded
    input_path: ''  ###
    input_size: [40, 56, 40]  #
    is_training: true
    jsn_path: ''  ###
    label_dtype: float32
    label_field_key: image/class/label
    num_channels: 1  #
    num_classes: 3  #
    output_size: []
    plans_file: ''  ###
    seed: null
    sharding: true
    shuffle_buffer_size: 100
    tf_data_service_address: null
    tf_data_service_job_name: null
    tfds_as_supervised: false
    tfds_data_dir: ''
    tfds_name: ''
    tfds_skip_decoding_feature: ''
    tfds_split: ''
  train_input_partition_dims: []
  validation_data:
    block_length: 1
    cache: false
    cycle_length: 10
    deterministic: null
    drop_remainder: false
    dtype: float32
    enable_tf_data_service: false
    file_type: tfrecord
    global_batch_size: 2  #
    image_field_key: image/encoded
    input_path: ''  ###
    input_size: [40, 56, 40]  #
    is_training: false
    jsn_path: ''  ###
    label_dtype: float32
    label_field_key: image/class/label
    num_channels: 1  #
    num_classes: 3  #
    output_size: []
    plans_file: ''  ###
    seed: null
    sharding: true
    shuffle_buffer_size: 1000
    tf_data_service_address: null
    tf_data_service_job_name: null
    tfds_as_supervised: false
    tfds_data_dir: ''
    tfds_name: ''
    tfds_skip_decoding_feature: ''
    tfds_split: ''
trainer:
  allow_tpu_summary: false
  best_checkpoint_eval_metric: ''
  best_checkpoint_export_subdir: ''
  best_checkpoint_metric_comp: higher
  checkpoint_interval: 10000
  continuous_eval_timeout: 3600
  eval_tf_function: true
  eval_tf_while_loop: false
  loss_upper_bound: 1000000.0
  max_to_keep: 5
  optimizer_config:
    ema: null
    learning_rate:
      polynomial:
        name: PolynomialDecay
        initial_learning_rate: 1.0e-02
        decay_steps: 250000
        end_learning_rate: 1.0e-06
        power: 0.9
        cycle: False
        offset: 0
      type: polynomial
    optimizer:
      sgd:
        clipnorm: null
        clipvalue: null
        decay: 0.00003
        global_clipnorm: null
        momentum: 0.99
        name: SGD
        nesterov: true
      type: sgd
    warmup:
      type: null
  recovery_begin_steps: 0
  recovery_max_trials: 0
  steps_per_loop: 50
  summary_interval: 50
  train_steps: 600
  train_tf_function: true
  train_tf_while_loop: true
  validation_interval: 50
  validation_steps: -1
  validation_summary_subdir: validation
